replicaCount: 1

image:
  repository: ghcr.io/your-org/vllm-gateway
  tag: "v1.0.0"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8080
  metricsPort: 9090

env:
  - name: MODEL_NAME
    value: "mistralai/Mistral-7B-Instruct-v0.2"
  - name: CUDA_VISIBLE_DEVICES
    value: "0"

resources:
  limits:
    nvidia.com/gpu: 1
    memory: 16Gi
    cpu: 4
  requests:
    nvidia.com/gpu: 1
    memory: 12Gi
    cpu: 2

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 4
  targetGPUUtilizationPercentage: 80

nodeSelector:
  node-type: gpu-worker

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

persistence:
  enabled: true
  storageClass: fast-ssd
  size: 50Gi
